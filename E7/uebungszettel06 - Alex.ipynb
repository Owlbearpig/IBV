{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Übungszettel 6</center></h1>\n",
    "<h2><center>Inhaltsbasierte Bild- und Videoanalyse - SoSe 19</center></h2>\n",
    "<h3><center>Abgabe: Di. 02.07.2019 - 12:00 Uhr</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs in Tensorflow (2+3+4+3+3 Punkte)\n",
    "\n",
    "In dieser Aufgabe soll ein neuronales Netz zur Klassifizierung von Bildern basierend\n",
    "auf dem CIFAR-10-Datensatz (https://www.cs.toronto.edu/~kriz/cifar.html)realisiert werden. Dazu soll die Tensorflow API Keras (https://keras.io/) verwendet werden.\n",
    "\n",
    "Der Datensatz besteht aus einem Trainings- und einem Testdatensatz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)  Preprocessing (2 Punkte)\n",
    "Laden Sie zunächst die Trainings- und Testdaten des CIFAR-10 Dataset herunter. Nutzen Sie dafür `keras.datasets.cifar`. Berechnen Sie dann das Meanbild und ziehen es von den Bildern in den Datasets ab. Teilen Sie jeden Input-Wert durch 128.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_train_mean_image = np.mean(x_train, axis=0, dtype='uint8')\n",
    "x_test_mean_image = np.mean(x_test, axis=0, dtype='uint8')\n",
    "\n",
    "x_train -= x_train_mean_image\n",
    "x_train = x_train / 128\n",
    "\n",
    "x_test -= x_test_mean_image\n",
    "x_test = x_test / 128\n",
    "\n",
    "y_train_mean_image = np.mean(y_train, axis=0, dtype='uint8')\n",
    "y_test_mean_image = np.mean(y_test, axis=0, dtype='uint8')\n",
    "\n",
    "y_train -= y_train_mean_image\n",
    "y_train = y_train / 128\n",
    "\n",
    "y_test -= y_test_mean_image\n",
    "y_test = y_test / 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)  Netzwerkarchitektur entwerfen (3 Punkte)\n",
    "Erzeugen Sie nun eine Netzwerkarchitektur die für Bilder aus dem CIFAR-10 Dataset Wahrscheinlichkeiten für 10 Klassen vorhersagt. Bauen Sie das Modell nach folgenden folgende Vorgaben:\n",
    "* Convolutional Layer: Aktivierung: ReLU, Kernel: 3x3, Padding: 1\n",
    "* Pooling-Size: 2x2\n",
    "* Struktur:\n",
    "    - Input: 32x32x3\n",
    "    \n",
    "    - Convolution (32 Filter)\n",
    "    - Batch Normalization\n",
    "    - Convolution (64 Filter)\n",
    "    - Batch Normalization\n",
    "    - Max-Pooling\n",
    "    \n",
    "    - Convolution (128 Filter)\n",
    "    - Batch Normalization\n",
    "    - Max-Pooling\n",
    "    \n",
    "    - Convolution (128 Filter)\n",
    "    - Batch Normalization\n",
    "    - Max-Pooling\n",
    "    \n",
    "    - Fully-Connected (256 Neuronen)\n",
    "    - Dropout (0.5)\n",
    "    - Batch Normalization\n",
    "    - Fully-Connected, 10 Outputs, Softmax-Aktivierung\n",
    "    \n",
    "Geben Sie auch die Struktur des Modells mit `model.summary()` aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0630 23:50:09.534320  9864 deprecation_wrapper.py:119] From e:\\pythons\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0630 23:50:09.724262  9864 deprecation_wrapper.py:119] From e:\\pythons\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0630 23:50:09.828231  9864 deprecation_wrapper.py:119] From e:\\pythons\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0630 23:50:09.955193  9864 deprecation_wrapper.py:119] From e:\\pythons\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0630 23:50:09.956193  9864 deprecation_wrapper.py:119] From e:\\pythons\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0630 23:50:10.217204  9864 deprecation_wrapper.py:119] From e:\\pythons\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0630 23:50:10.361279  9864 deprecation_wrapper.py:119] From e:\\pythons\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0630 23:50:10.610106  9864 deprecation.py:506] From e:\\pythons\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 377,162\n",
      "Trainable params: 375,946\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(32,32,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)  Training (4 Punkte)\n",
    "Trainieren Sie nun das Netz mit Stochastic Gradient Descent auf dem Trainingsdatensatz.\n",
    "Nutzen Sie dafür das Nesterov Verfahren und setzen Sie sinnvolle Werte für Batchsize und Startlernrate.\n",
    "\n",
    "Verwenden Sie Callbacks für TensorBoard (mit Bildern und Graph) und ReduceLROnPlateau (mögliche Werte: factor=0.1, patience=3, min_delta=0.001, min_lr=0.0001). \n",
    "Trainieren Sie das Modell für mindestens 10 Epochen. Nach etwa 50-100 Epochen sollten Sie gute Ergebnisse erhalten.\n",
    "Binden Sie ein Bild der Losskurve in dieses Notebook ein.\n",
    "Vergessen Sie nicht, das Modell zu speichern. Fügen Sie das gespeicherte (finale) Modell ihrer Abgabe hinzu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0630 23:50:10.654095  9864 deprecation_wrapper.py:119] From e:\\pythons\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0630 23:50:26.495965  9864 deprecation_wrapper.py:119] From e:\\pythons\\python37\\lib\\site-packages\\keras\\callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0630 23:50:26.496964  9864 deprecation_wrapper.py:119] From e:\\pythons\\python37\\lib\\site-packages\\keras\\callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.0262 - val_loss: 0.0024\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 355s 7ms/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 348s 7ms/step - loss: 0.0091 - val_loss: 0.0047\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 349s 7ms/step - loss: 0.0105 - val_loss: 4.2639e-04\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 349s 7ms/step - loss: 0.0018 - val_loss: 1.0827e-04\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 356s 7ms/step - loss: 2.5227e-04 - val_loss: 1.9713e-05\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 354s 7ms/step - loss: 1.2373e-04 - val_loss: 2.4041e-06\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 355s 7ms/step - loss: 7.9335e-05 - val_loss: 3.8525e-06\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 347s 7ms/step - loss: 7.6695e-05 - val_loss: 3.1218e-06\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 354s 7ms/step - loss: 8.6716e-05 - val_loss: 3.3526e-06\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b1f90c5f60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=1, write_graph=True, write_images=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.0001, min_delta=0.001, verbose=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tbCallBack, reduce_lr])\n",
    "\n",
    "model.save('CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### c)  Testen (3 Punkte)\n",
    "Laden Sie das zuvor trainierte Modell. Evaluieren Sie nun das Modell auf den Testdaten.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)  Anwenden (3 Punkte)\n",
    "Laden Sie das zuvor trainierte Modell. Wenden Sie das Modell auf 10 zufällig ausgewählte Bilder aus dem Testdatensatz an. Visualisieren Sie die Ergebnisse. Geben Sie dazu das Bild aus und die vorhergesagte Wahrscheinlichkeite für jede der 10 Klassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
