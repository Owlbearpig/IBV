{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Übungszettel 4</center></h1>\n",
    "<h2><center>Inhaltsbasierte Bild- und Videoanalyse - SoSe 19</center></h2>\n",
    "\n",
    "Hinweis: Alle Lösungen sollen in einem IPython Notebook realisiert werden, wobei Teilaufgaben und Zwischenergebnisse ausgegeben bzw. visualisiert werden sollen. Die Übungszettel sollen in Gruppen von 3 Personen abgegeben werden. Die Datei soll nach folgendem Muster benannt werden: uebung01 {nachname1} {nachname2} {nachname3}.ipynb\n",
    "\n",
    "Für eine Einleitung in IPython siehe z.B.: http://cs231n.github.io/ipython-tutorial/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1 - Künstliche Neuronale Netze\n",
    "\n",
    "### Aufgabe 1.1: Grundlagen (0,5+0,5+0,5+0,5+0,5 Punkte)\n",
    "\n",
    "##### a) Erklären Sie den Unterschied zwischen Trainings-, Validierungs- und Testdatensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den gesammten Datensatz der zum Training eines Neuronales Netzes genutzt wird teilt man im allgemeinen in drei Datensätz auf.\n",
    "Der **Trainingsdatensatz** (meist zusätzlich in sg. Batches unterteilt) wird zum eigentlichen Training des Netzes benutzt.\n",
    "\n",
    "Auf dem **Validierungsdatensatz** wird überprüft ob das Netzwerk auch das gelernt hat was wir von ihm wollen und nicht etwa nur die Trainingsdatensäze auswendig kann.\n",
    "\n",
    "Der Test wie gut das trainierte Netz abschneidet, wird mit hilfe des **Testdatensatzes** durchgeführt. Mit diesen frischen, dem Netz unbekannten Daten kann dann etwa die *accuracy* bestimmt werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Erklären Sie den Begriff Overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting beschreibt den Prozess, wenn ein Netzwerk die Trainingsdaten auswendig lernt. Anstatt allgemeiner Features herauszuarbeiten, werden Features erlernt, die zu sehr den Trainingsdaten entsprechen. Somit schneidet das Netz zwar auf den Trainingsdaten großartig ab, kann aber mit neuen Daten nicht umgehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Was bewirken L1 und L2 Regularisierung?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularisierung addiert eine \"Strafe\" auf die Loss Funktion, je nachdem wie komplex das Netz wird. Hierdurch soll dem Overfitting entgegen gewirkt werden.\n",
    "\n",
    "**L1**\n",
    "$$ R(W) = \\sum_{k} \\sum_{l} |W_{k,l}| $$\n",
    "**L2**\n",
    "$$ R(W) = \\sum_{k} \\sum_{l} W_{k,l}^2 $$\n",
    "Die L2 Regularisierung bestraft vorallem hohe Gewichtungen, deutlich stärker als L1, indem sie das Quadrat des Gewichtes auf die Lossfunktion aufaddiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Geben Sie die mathematische Definition eines Neurons an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Neuron ist eine Funktion die die mit den Gewichten $ w_i $ gewichtete und um den Bias $ b $ verschobene Summe aller Inputs $ x_i $ mit Hilfe einer Aktivierungsfunktion $ f $ auf einen output $ y $ abildet.\n",
    "\n",
    "$$ y = f(\\sum_{i=0} w_i x_i + b) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Erklären Sie die Begriffe Vektor, Matrix und Tensor im Kontext von neuronalen Netzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1.2: Backpropagation (5,5+1 Punkte)\n",
    "\n",
    "Mathematische Ausdrücke sollen in den folgenden Teilaufgaben in Latex eingebunden werden.\n",
    "\n",
    "#### a) Berechnen Sie die Werte $\n",
    "f_1, f_2, f_3, f_4, f_t,\n",
    "\\frac{df_t}{dw_0},\n",
    "\\frac{df_t}{dw_1},\n",
    "\\frac{df_t}{dw_2},\n",
    "\\frac{df_t}{dx_0},\n",
    "\\frac{df_t}{dx_1},\n",
    "\\frac{df_t}{dx_2},\n",
    "\\frac{df_t}{db},\n",
    "\\frac{df_t}{df_1},\n",
    "\\frac{df_t}{df_2},\n",
    "\\frac{df_t}{df_3},\n",
    "\\frac{df_t}{df_4}, \\frac{df_t}{df_t}.\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"tanh_graph.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f_1 = \\\\\n",
    "f_2 = \\\\\n",
    "f_3 = \\\\\n",
    "f_4 = \\\\\n",
    "f_t = \\\\\n",
    "\\frac{df_t}{dw_0} = \\\\\n",
    "\\frac{df_t}{dw_1} = \\\\\n",
    "\\frac{df_t}{dw_2} = \\\\\n",
    "\\frac{df_t}{dx_0} = \\\\\n",
    "\\frac{df_t}{dx_1} = \\\\\n",
    "\\frac{df_t}{dx_2} = \\\\\n",
    "\\frac{df_t}{db} = \\\\\n",
    "\\frac{df_t}{df_1} = \\\\\n",
    "\\frac{df_t}{df_2} = \\\\\n",
    "\\frac{df_t}{df_3} = \\\\\n",
    "\\frac{df_t}{df_4} = \\\\\n",
    "\\frac{df_t}{df_t} = \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Wo wird die multivariate Kettenregel bei der Error Backpropagation in neuronalen Netzen angewendet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Kettenregel wird in Neuronalen Netzen angewendet um den Gradiente zu bestimmen, mit dem im sg. *Gradient descent* Verfahren der nächste Optimierungs-Schritt bestimmt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax (1+1+1+1+2 Punkte)\n",
    "\n",
    "Die Softmaxfunktion wird genutzt, um die Ausgaben eines neuronalen Netzes als Wahrscheinlichkeitsverteilung über $K$ Klassen zu repräsentieren. Die Wahrscheinlichkeit für eine Klasse $j$ ist also\n",
    "$p_j = \\frac{e^{o_j}}{\\sum_{k=1}^K e^{o_k}}$. Oft wird ein neuronales Netz auf logarithmischen Loss optimiert. Dieser ist definiert als $ L = -\\sum_j y_j \\log p_j $.\n",
    "\n",
    "Nehmen Sie an, dass das Netz eine von drei Klassen vorraussagen soll und für ein bestimmtes Beispiel die Ausgabe $\\hat{p}=\\begin{pmatrix}0.23\\\\0.26\\\\0.51\\end{pmatrix} $ liefert und die dritte Klasse die richtige ist, also $\\hat{y}=\\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix} $.\n",
    "\n",
    "Mathematische Ausdrücke sollen in den folgenden Teilaufgaben in Latex eingebunden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Geben Sie den Loss $L$ für $\\hat{p}$ an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Berechnen Sie $\\frac{\\partial L}{\\partial p_i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Geben $ \\nabla_{p} L$ für $\\hat{p}$ an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Zeigen Sie für die Ableitung der Softmaxfunktion, dass folgendes gilt:\n",
    "\n",
    "1) $\\frac{\\partial p_j}{\\partial o_i} = -p_ip_j, \\;\\;\\;\\; j\\ne i$\n",
    "\n",
    "2) $\\frac{\\partial p_j}{\\partial o_i} = p_i(1-p_i),    \\;\\;\\;\\; j=i$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Zeigen Sie, dass gilt: $ \\frac{\\partial L}{\\partial o_i} = p_i-y_i $\n",
    "(Hinweis: Nutzen Sie die Gleichungen aus Aufgabenteil d))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
